\section{Evaluation}

Our evaluation will be articulated in two parts. Firstly, we will compare the content extraction procedure presented in section \ref{algorithms} with three open source projects capable of generically extract content from web articles. The comparison will show that our blog targeted solution has better performances both in term of precision and running time. Secondly, a discussion will be held regarding the different alternative to archive data beyong HTML

% intro, plan
% hard to evaluate anything else, ttbook we r z only 1


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Content extraction}

% intro, plan

% other projects
% \item Boilerpipe https://github.com/misja/python-boilerpipe
% \item Goose https://github.com/grangier/python-goose
% \item Readability https://github.com/buriy/python-readability
% limitation because different approach

% dataset
% result (table)
\precisionTable
% discussion (15 feed entry)

% running time setup (single core, gc disabled, measure time spent in respective extraction functions)
% result (plot)
\input{testfigure.tex}

% discussion (c++ vs java vs scala vs go \cite{hundt2011})


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{JavaScript rendering}

% intro, plan (why we pick these projects, what we want to show with this evaluation)

% \item "Wget crawl" http://blogforever.eu/blog/2011/05/21/creating-a-snapshot-of-a-blog-post-using-wget/
% \item wkhtmltopdf http://code.google.com/p/wkhtmltopdf/ http://blogforever.eu/blog/2011/05/17/rendering-and-storing-web-pages-using-wkhtmltopdf/
% \item OXPath
% \item Selenium + full browser

% table to recap

% discussion (ez of use vs power, fine because it's automated)

