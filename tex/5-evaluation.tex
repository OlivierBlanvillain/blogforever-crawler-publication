\section{Evaluation}

Our evaluation will be articulated in two parts. Firstly, we will compare the content extraction procedure presented in section \ref{algorithms} with three open source projects capable of generically extract content from web articles. The comparison will show that our blog targeted solution has better performances both in term of running time and success rates. Secondly, a discussion will be held regarding the different solutions available to archive data beyond what is available in HTML source code. Extraction of authors, dates and comments is not part of the evaluation because of the lack of publicly available competing projects and reference data sets.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Content extraction}
The evaluation of post content extraction we compared our approach to three open source projects: Readability\cite{}, Boilerpipe\cite{} and Goose\cite{}. Implemented in Javascript, Java and Scala respectively, all three offer the same functionality: given an HTML web page, extract it's main textual content. These projects are more generic than our blog specific approach in the sense that they do not make use of web feeds and do not exploit the fact that pages of a same blog share a similar HTML structure (assuptions \ref{havefeedAssum} and \ref{similarhtmlAssum}). Readability works by .... Boilerpipe uses a very .... Goose implements a more sofisticated algorithm which ....

Table \ref{precisionTable} shows the

Success rates of post content extraction

To evaluate post content extraction
\cite{burton2011} % <- dataset
% intro, plan

% other projects
% \item Boilerpipe https://github.com/misja/python-boilerpipe
% \item Goose https://github.com/grangier/python-goose
% \item Readability https://github.com/buriy/python-readability
% limitation because different approach
Success rates of Content extraction is evaluation

% dataset
% result (table)
\precisionTable
% discussion (15 feed entry)

% running time setup (single core, gc disabled, measure time spent in respective extraction functions)
% result (plot)
\input{testfigure.tex}

% discussion (c++ vs java vs scala vs go \cite{hundt2011})


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{JavaScript rendering}

% intro, plan (why we pick these projects, what we want to show with this evaluation)

% \item "Wget crawl" http://blogforever.eu/blog/2011/05/21/creating-a-snapshot-of-a-blog-post-using-wget/
% \item wkhtmltopdf http://code.google.com/p/wkhtmltopdf/ http://blogforever.eu/blog/2011/05/17/rendering-and-storing-web-pages-using-wkhtmltopdf/
% \item OXPath
% \item Selenium + full browser

% table to recap

% discussion (ez of use vs power, fine because it's automated)

